{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "print (x_train.shape)\n",
    "print (x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(latent_dim, activation=\"relu\")\n",
    "        ])\n",
    "        \n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(784, activation=\"sigmoid\"),\n",
    "            layers.Reshape((28, 28))\n",
    "        ])\n",
    "    \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "autoencoder = Autoencoder(latent_dim)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train, \n",
    "                x_train, \n",
    "                epochs=10, \n",
    "                shuffle=True, \n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i])\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "x_train = x_train[..., tf.newaxis] # add extra dim to the data\n",
    "x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_factor = 0.2\n",
    "\n",
    "x_train_noisy = x_train + noise_factor * tf.random.normal(shape=x_train.shape)\n",
    "x_test_noisy = x_test + noise_factor * tf.random.normal(shape=x_test.shape)\n",
    "\n",
    "x_train_noisy = tf.clip_by_value(x_train_noisy, clip_value_min=0., clip_value_max=1.)\n",
    "x_test_noisy = tf.clip_by_value(x_test_noisy, clip_value_min=0., clip_value_max=1.) # ensures that all pixel values are between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(n):\n",
    "    ax = plt.subplot(1, n, i + 1)\n",
    "    plt.title(\"original + noise\")\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoise(Model):\n",
    "    def __init__(self):\n",
    "        super(Denoise, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(28, 28, 1)),\n",
    "            layers.Conv2D(16, (3, 3), activation='relu', padding='same', strides=2),\n",
    "            layers.Conv2D(8, (3, 3), activation='relu', padding='same', strides=2)\n",
    "        ])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Conv2DTranspose(8, kernel_size=2, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2DTranspose(16, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')\n",
    "            ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "autoencoder = Denoise()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(x_train_noisy, x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_noisy, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = autoencoder.encoder(x_test_noisy).numpy()\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "\n",
    "    # display original + noise\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.title(\"original + noise\")\n",
    "    plt.imshow(tf.squeeze(x_test_noisy[i]))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    bx = plt.subplot(2, n, i + n + 1)\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.imshow(tf.squeeze(decoded_imgs[i]))\n",
    "    plt.gray()\n",
    "    bx.get_xaxis().set_visible(False)\n",
    "    bx.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomaly Detection\n",
    "\n",
    "An autoencoder is trained to minimize reconstruction error. Train an autoencoder on the normal rhythms only, then use it to reconstruct all the data. Our hypothesis is that the abnormal rhythms will have higher reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "      <th>140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.112522</td>\n",
       "      <td>-2.827204</td>\n",
       "      <td>-3.773897</td>\n",
       "      <td>-4.349751</td>\n",
       "      <td>-4.376041</td>\n",
       "      <td>-3.474986</td>\n",
       "      <td>-2.181408</td>\n",
       "      <td>-1.818286</td>\n",
       "      <td>-1.250522</td>\n",
       "      <td>-0.477492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792168</td>\n",
       "      <td>0.933541</td>\n",
       "      <td>0.796958</td>\n",
       "      <td>0.578621</td>\n",
       "      <td>0.257740</td>\n",
       "      <td>0.228077</td>\n",
       "      <td>0.123431</td>\n",
       "      <td>0.925286</td>\n",
       "      <td>0.193137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.100878</td>\n",
       "      <td>-3.996840</td>\n",
       "      <td>-4.285843</td>\n",
       "      <td>-4.506579</td>\n",
       "      <td>-4.022377</td>\n",
       "      <td>-3.234368</td>\n",
       "      <td>-1.566126</td>\n",
       "      <td>-0.992258</td>\n",
       "      <td>-0.754680</td>\n",
       "      <td>0.042321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538356</td>\n",
       "      <td>0.656881</td>\n",
       "      <td>0.787490</td>\n",
       "      <td>0.724046</td>\n",
       "      <td>0.555784</td>\n",
       "      <td>0.476333</td>\n",
       "      <td>0.773820</td>\n",
       "      <td>1.119621</td>\n",
       "      <td>-1.436250</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.567088</td>\n",
       "      <td>-2.593450</td>\n",
       "      <td>-3.874230</td>\n",
       "      <td>-4.584095</td>\n",
       "      <td>-4.187449</td>\n",
       "      <td>-3.151462</td>\n",
       "      <td>-1.742940</td>\n",
       "      <td>-1.490659</td>\n",
       "      <td>-1.183580</td>\n",
       "      <td>-0.394229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886073</td>\n",
       "      <td>0.531452</td>\n",
       "      <td>0.311377</td>\n",
       "      <td>-0.021919</td>\n",
       "      <td>-0.713683</td>\n",
       "      <td>-0.532197</td>\n",
       "      <td>0.321097</td>\n",
       "      <td>0.904227</td>\n",
       "      <td>-0.421797</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.490473</td>\n",
       "      <td>-1.914407</td>\n",
       "      <td>-3.616364</td>\n",
       "      <td>-4.318823</td>\n",
       "      <td>-4.268016</td>\n",
       "      <td>-3.881110</td>\n",
       "      <td>-2.993280</td>\n",
       "      <td>-1.671131</td>\n",
       "      <td>-1.333884</td>\n",
       "      <td>-0.965629</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350816</td>\n",
       "      <td>0.499111</td>\n",
       "      <td>0.600345</td>\n",
       "      <td>0.842069</td>\n",
       "      <td>0.952074</td>\n",
       "      <td>0.990133</td>\n",
       "      <td>1.086798</td>\n",
       "      <td>1.403011</td>\n",
       "      <td>-0.383564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800232</td>\n",
       "      <td>-0.874252</td>\n",
       "      <td>-2.384761</td>\n",
       "      <td>-3.973292</td>\n",
       "      <td>-4.338224</td>\n",
       "      <td>-3.802422</td>\n",
       "      <td>-2.534510</td>\n",
       "      <td>-1.783423</td>\n",
       "      <td>-1.594450</td>\n",
       "      <td>-0.753199</td>\n",
       "      <td>...</td>\n",
       "      <td>1.148884</td>\n",
       "      <td>0.958434</td>\n",
       "      <td>1.059025</td>\n",
       "      <td>1.371682</td>\n",
       "      <td>1.277392</td>\n",
       "      <td>0.960304</td>\n",
       "      <td>0.971020</td>\n",
       "      <td>1.614392</td>\n",
       "      <td>1.421456</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.112522 -2.827204 -3.773897 -4.349751 -4.376041 -3.474986 -2.181408   \n",
       "1 -1.100878 -3.996840 -4.285843 -4.506579 -4.022377 -3.234368 -1.566126   \n",
       "2 -0.567088 -2.593450 -3.874230 -4.584095 -4.187449 -3.151462 -1.742940   \n",
       "3  0.490473 -1.914407 -3.616364 -4.318823 -4.268016 -3.881110 -2.993280   \n",
       "4  0.800232 -0.874252 -2.384761 -3.973292 -4.338224 -3.802422 -2.534510   \n",
       "\n",
       "        7         8         9    ...       131       132       133       134  \\\n",
       "0 -1.818286 -1.250522 -0.477492  ...  0.792168  0.933541  0.796958  0.578621   \n",
       "1 -0.992258 -0.754680  0.042321  ...  0.538356  0.656881  0.787490  0.724046   \n",
       "2 -1.490659 -1.183580 -0.394229  ...  0.886073  0.531452  0.311377 -0.021919   \n",
       "3 -1.671131 -1.333884 -0.965629  ...  0.350816  0.499111  0.600345  0.842069   \n",
       "4 -1.783423 -1.594450 -0.753199  ...  1.148884  0.958434  1.059025  1.371682   \n",
       "\n",
       "        135       136       137       138       139  140  \n",
       "0  0.257740  0.228077  0.123431  0.925286  0.193137  1.0  \n",
       "1  0.555784  0.476333  0.773820  1.119621 -1.436250  1.0  \n",
       "2 -0.713683 -0.532197  0.321097  0.904227 -0.421797  1.0  \n",
       "3  0.952074  0.990133  1.086798  1.403011 -0.383564  1.0  \n",
       "4  1.277392  0.960304  0.971020  1.614392  1.421456  1.0  \n",
       "\n",
       "[5 rows x 141 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('http://storage.googleapis.com/download.tensorflow.org/data/ecg.csv', header=None)\n",
    "raw_data = dataframe.values\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_data[:, -1]\n",
    "data = raw_data[:, 0:-1]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    data, labels, test_size=0.2, random_state=21\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalize the Data**\n",
    "\n",
    "Autoencoders are often used for anomaly detection, where the model learns to reconstruct normal patterns. Anomalies are deviations from these normal patterns. By normalizing the data to [0, 1], you provide a consistent range for the input values, making it easier for the autoencoder to identify anomalies that fall outside this range.\n",
    "\n",
    "- `(train_data - min_val)` subtracts the minimum value from each data point, ensuring that the minimum value becomes 0.\n",
    "- `(max_val - min_val)` calculates the range of values (the difference between the maximum and minimum values).\n",
    "- Dividing `(train_data - min_val)` by `(max_val - min_val)` scales the data between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data to [0, 1]\n",
    "min_val = tf.reduce_min(train_data)\n",
    "max_val = tf.reduce_max(train_data)\n",
    "\n",
    "train_data = (train_data - min_val) / (max_val - min_val) \n",
    "test_data = (test_data - min_val) / (max_val - min_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
